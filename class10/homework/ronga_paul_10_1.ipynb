{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import each file into its own row in a dataframeâ€¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20417 files read, 55 errors.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "x = 0\n",
    "err = 0\n",
    "content_list = []\n",
    "for file in glob.glob('20_newsgroups/*/*'):\n",
    "    theme = file.split('/')[1]\n",
    "    with open(file, 'r') as f:\n",
    "        try:\n",
    "            content_list.append({'Theme':theme, 'Content':f.read()})\n",
    "        except ValueError as e:\n",
    "            err += 1\n",
    "            #print('Error with file', file, \"->\", e)\n",
    "    x += 1\n",
    "#    if x > 1500:\n",
    "#        break\n",
    "print(x, \"files read,\", err, \"errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20357</th>\n",
       "      <td>In article &lt;930426.140835.4f1.rusnews.w165w@ma...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20358</th>\n",
       "      <td>In article &lt;1993Apr27.073723.18577@csis.dit.cs...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20359</th>\n",
       "      <td>In article &lt;1rc1f3INN7rl@emx.cc.utexas.edu&gt; \\n...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20360</th>\n",
       "      <td>In article &lt;1993Apr26.231845.13843@digi.lonest...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20361</th>\n",
       "      <td>In article &lt;C64H4w.BFH@darkside.osrhe.uoknor.e...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content               Theme\n",
       "20357  In article <930426.140835.4f1.rusnews.w165w@ma...  talk.religion.misc\n",
       "20358  In article <1993Apr27.073723.18577@csis.dit.cs...  talk.religion.misc\n",
       "20359  In article <1rc1f3INN7rl@emx.cc.utexas.edu> \\n...  talk.religion.misc\n",
       "20360  In article <1993Apr26.231845.13843@digi.lonest...  talk.religion.misc\n",
       "20361  In article <C64H4w.BFH@darkside.osrhe.uoknor.e...  talk.religion.misc"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use the LabelEncoder to convert the group names to numeric labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Theme_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20357</th>\n",
       "      <td>In article &lt;930426.140835.4f1.rusnews.w165w@ma...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20358</th>\n",
       "      <td>In article &lt;1993Apr27.073723.18577@csis.dit.cs...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20359</th>\n",
       "      <td>In article &lt;1rc1f3INN7rl@emx.cc.utexas.edu&gt; \\n...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20360</th>\n",
       "      <td>In article &lt;1993Apr26.231845.13843@digi.lonest...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20361</th>\n",
       "      <td>In article &lt;C64H4w.BFH@darkside.osrhe.uoknor.e...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content               Theme  \\\n",
       "20357  In article <930426.140835.4f1.rusnews.w165w@ma...  talk.religion.misc   \n",
       "20358  In article <1993Apr27.073723.18577@csis.dit.cs...  talk.religion.misc   \n",
       "20359  In article <1rc1f3INN7rl@emx.cc.utexas.edu> \\n...  talk.religion.misc   \n",
       "20360  In article <1993Apr26.231845.13843@digi.lonest...  talk.religion.misc   \n",
       "20361  In article <C64H4w.BFH@darkside.osrhe.uoknor.e...  talk.religion.misc   \n",
       "\n",
       "       Theme_id  \n",
       "20357        19  \n",
       "20358        19  \n",
       "20359        19  \n",
       "20360        19  \n",
       "20361        19  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "themes_list = list(set(df['Theme']))\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(themes_list)\n",
    "df['Theme_id'] = df['Theme'].apply(le.transform)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pick out 10 words or phrases to use as manually created features. Doing an 80/20 train/test split, how well does a Naive Bayes classifier do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God > 1379\n",
      "gun > 1061\n",
      "car > 4958\n",
      "sci > 1700\n",
      "space > 1028\n",
      "society > 409\n",
      "mac > 1651\n",
      "computer > 1020\n",
      "chip > 777\n",
      "game > 1267\n",
      "Total: 20362\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"God\",\n",
    "    \"gun\",\n",
    "    \"car\",\n",
    "    \"sci\",\n",
    "    \"space\",\n",
    "    \"society\",\n",
    "    \"mac\",\n",
    "    \"computer\",\n",
    "    \"chip\",\n",
    "    \"game\"\n",
    "]\n",
    "\n",
    "feature_cols = []\n",
    "for word in features:\n",
    "    df['has_' + word] = df['Content'].str.contains(word)\n",
    "    feature_cols.append('has_' + word)\n",
    "    print(word, '>', len(df) - df['has_' + word].value_counts()[0])\n",
    "print(\"Total:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[feature_cols],\n",
    "    df['Theme_id'],\n",
    "    test_size=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.197311068819\n",
      "0.19641541861\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "clf = naive_bayes.BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use a CountVectorizer to automatically create your list of features. Doing an 80/20 train/test split, how well can a Naive Bayes classifier do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 608 ms, total: 22.1 s\n",
      "Wall time: 22.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time vectorizer.fit(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "every_single_word_features = vectorizer.transform(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.199152802505\n",
      "0.199116130616\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[feature_cols],\n",
    "    df['Theme_id'],\n",
    "    test_size=.2\n",
    ")\n",
    "clf = naive_bayes.BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. PUSH THAT SCORE UP! You can adjust ngrams, max_features and any other options of the vectorizer, or try a decision tree or any other type of classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ngram_range : tuple (min_n, max_n)\n",
    "    The lower and upper boundary of the range of n-values for different\n",
    "    n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
    "    will be used.\n",
    "    \n",
    "stop_words : string {'english'}, list, or None (default)\n",
    "    If 'english', a built-in stop word list for English is used.  \n",
    "    \n",
    "max_features : int or None, default=None\n",
    "    If not None, build a vocabulary that only consider the top\n",
    "    max_features ordered by term frequency across the corpus.\n",
    "\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=20000, stop_words='english')\n",
    "# 200 -> 0.41, 0.39\n",
    "# 500 -> 0.55, 0.51\n",
    "# 5000 -> 0.75, 0.7\n",
    "# 10000 -> 0.777, 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 s, sys: 1.07 s, total: 32.1 s\n",
      "Wall time: 32.2 s\n",
      "CPU times: user 11.7 s, sys: 69.1 ms, total: 11.7 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%time vectorizer.fit(df['Content'])\n",
    "%time every_single_word_features = vectorizer.transform(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20362, 20000)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every_single_word_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78691141261\n",
      "0.719616989934\n",
      "[16 14  5 ..., 12 18 17]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    every_single_word_features,\n",
    "    df['Theme_id'],\n",
    "    test_size=.2\n",
    ")\n",
    "clf = naive_bayes.BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YEAH!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"TSN Sportsdesk just reported that the OTTAWA SUN has reported that\",\n",
    "    \"I love science fiction\",\n",
    "    \"Car, cars are my wheels\",\n",
    "    \"Do you believe in God?\",\n",
    "    \"Jet Set Willy is the best game ever.\",\n",
    "    \"I wish my mum boughts me a Hummer\",\n",
    "    \"Windows sucks, man, my computer freezed again!\",\n",
    "    \"The probability of dying from toe cancer is higher than you think.\",\n",
    "    \"Move hard and break stuff\",\n",
    "    \"Basketball is the best sport ever\",\n",
    "    \"Guns should be banned, I think\",\n",
    "    \"Windows Mac OS hardware\",\n",
    "    \"Basketball goals football hockey stuff\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (13, 20000) \n",
      "\n",
      "TSN Sportsdesk just reported that the OTTAWA SUN has reported that -> misc.forsale\n",
      "I love science fiction -> misc.forsale\n",
      "Car, cars are my wheels -> misc.forsale\n",
      "Do you believe in God? -> misc.forsale\n",
      "Jet Set Willy is the best game ever. -> misc.forsale\n",
      "I wish my mum boughts me a Hummer -> misc.forsale\n",
      "Windows sucks, man, my computer freezed again! -> misc.forsale\n",
      "The probability of dying from toe cancer is higher than you think. -> misc.forsale\n",
      "Move hard and break stuff -> misc.forsale\n",
      "Basketball is the best sport ever -> misc.forsale\n",
      "Guns should be banned, I think -> misc.forsale\n",
      "Windows Mac OS hardware -> misc.forsale\n",
      "Basketball goals football hockey stuff -> misc.forsale\n"
     ]
    }
   ],
   "source": [
    "sentences_features = vectorizer.transform(sentences)\n",
    "print('Shape:', sentences_features.shape, \"\\n\")\n",
    "results = clf.predict(sentences_features)\n",
    "for sentence, theme in zip(sentences, results):\n",
    "    print(sentence, '->', le.inverse_transform(theme))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Maybe 20000 isn't enough...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
