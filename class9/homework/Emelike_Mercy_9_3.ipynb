{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import stuff \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## STEP 1: DATA IMPORT AND PREPROCESSING ##########\n",
    "\n",
    "# Here we're taking in the training data and splitting it into two lists: One with the text of\n",
    "# each bill title, and the second with each bill title's corresponding category. Order is important.\n",
    "# The first bill in list 1 should also be the first category in list 2.\n",
    "training = [line.strip().split('|') for line in open('../data/bills_training.txt', 'r').readlines()]\n",
    "text = [t[0] for t in training if len(t) > 1]\n",
    "labels = [t[1] for t in training if len(t) > 1]\n",
    "\n",
    "# A little bit of cleanup for scikit-learn's benefit. Scikit-learn models wants our categories to\n",
    "# be numbers, not strings. The LabelEncoder performs this transformation.\n",
    "# Assigns LabelEncoder to variable, encoder\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "# Fits encoder to labels list. Returns an array. \n",
    "correct_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## STEP 2: FEATURE EXTRACTION ##########\n",
    "\n",
    "# CountVectorizer implements both tokenization and occurrence counting in a single class\n",
    "# Tokenization is the process of rocess of breaking a stream of text up into words, \n",
    "# phrases, symbols, or other meaningful elements called tokens \n",
    "# The CountVectorizer gives a token id for each possible token, for instance using white space and punctuation as token\n",
    "# separators. \n",
    "# Occurrence counting is counting the occurrence of tokens in a document \n",
    "# Stop_words is a parameter of the CountVectorizer. When set to 'english' a built-in stop word list for English is used\n",
    "# Here, we are assigning the countvectorizer to a variable called vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# The fit_transform method learns the vocabulary dictionary and returns term-document matrix (array)\n",
    "# The array has samples (which are lines of text separated by stop words) as its rows and features as it columns\n",
    "# The array is filled with 0/1, 0 this feature is not in the sample, 1 it is. \n",
    "# Here, we fit the vectorizer on the text list. The vectorizer returns an array. \n",
    "# We assign this array to a variable called data\n",
    "data = vectorizer.fit_transform(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## STEP 3: MODEL BUILDING ##########\n",
    "\n",
    "# DecisionTreeClassifier() that predicts the value of a target variable by learning simple decision rules inferred from \n",
    "# the data features\n",
    "# Assign classifer to variable, model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model on the features array to predict the correct labels \n",
    "fit_model = model.fit(data, correct_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mercyemelike/.virtualenvs/data_analysis/lib/python3.5/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "# ########## STEP 4: EVALUATION ##########\n",
    "\n",
    "# Evaluate our model with 10-fold cross-validation\n",
    "# This means that we split the data into five sections \n",
    "# Then we split those five sections into five sections \n",
    "# Train on four sections, test on one section, repeat\n",
    "# save scores to variable \n",
    "\n",
    "scores = cross_validation.cross_val_score(model, data, correct_labels, cv=5)\n",
    "\n",
    "# Print the mean and standard deviation of the scores from cross validation\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public postsecondary education: executive officer compensation. -> ['Education']\n",
      "An act to add Section 236.3 to the Education code, related to the pricing of college textbooks. -> ['Education']\n",
      "Political Reform Act of 1974: campaign disclosures. -> ['Campaign Finance and Election Issues']\n",
      "An act to add Section 236.3 to the Penal Code, relating to human trafficking. -> ['Crime']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mercyemelike/.virtualenvs/data_analysis/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/mercyemelike/.virtualenvs/data_analysis/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/mercyemelike/.virtualenvs/data_analysis/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/mercyemelike/.virtualenvs/data_analysis/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# ########## STEP 5: APPLYING THE MODEL ##########\n",
    "\n",
    "# Samples to use in the model\n",
    "docs_new = [\"Public postsecondary education: executive officer compensation.\",\n",
    "            \"An act to add Section 236.3 to the Education code, related to the pricing of college textbooks.\",\n",
    "            \"Political Reform Act of 1974: campaign disclosures.\",\n",
    "            \"An act to add Section 236.3 to the Penal Code, relating to human trafficking.\"\n",
    "        ]\n",
    "\n",
    "# Apply vectorizer to the test samples, save to variable, test_data\n",
    "test_data = vectorizer.transform(docs_new)\n",
    "\n",
    "# Loop through elements of docs_new \n",
    "# Print, string assigment, row i in docs_new --> string resulting from calling the labelencoder (assigned in step 1) \n",
    "# with classes attribute\n",
    "# The classes attribute holds labels for each class\n",
    "# Pass predictions of labels for test_data into the encoder\n",
    "for i in range(len(docs_new)):\n",
    "    print('%s -> %s' % (docs_new[i], encoder.classes_[model.predict(test_data.toarray()[i])]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
